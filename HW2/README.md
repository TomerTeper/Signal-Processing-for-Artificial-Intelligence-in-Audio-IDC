# Homework 2: PCA with a Linear Autoencoder

## Overview
This homework assignment explores the use of a **linear autoencoder** to approximate **Principal Component Analysis (PCA)** using a neural network. The goal is to apply fundamental deep learning tools to understand and visualize how autoencoders can replicate the behavior of PCA in reducing data dimensionality.

The implementation is done in **TensorFlow** (Keras-compatible syntax), and includes practical exercises with synthetic datasets to illustrate key concepts.

## Key Topics Covered
- Dimensionality reduction  
- Principal Component Analysis (PCA)  
- Linear autoencoders  
- Neural network construction and training  
- TensorFlow/Keras usage  

## Structure
The notebook is structured around the following main sections:
1. **Data Generation**: Synthetic sine wave data with noise.  
2. **Autoencoder Design**: Construction of a linear encoder and decoder.  
3. **Training**: Using TensorFlow to train the model on noisy data.  
4. **Visualization**: Comparing original, noisy, and reconstructed signals.  
5. **Comparison with PCA**: Analyzing the effectiveness of the autoencoder relative to PCA.  

## Requirements
- Python 3.x  
- TensorFlow (>=2.x)  
- Numpy  
- Matplotlib  
